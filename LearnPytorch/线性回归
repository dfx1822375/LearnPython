import numpy as np
import matplotlib.pyplot as plt
from torch import nn,optim
from torch.autograd import Variable
import torch
# import numpy as np
# # https://pytorch.org/docs/torch
# x = th.rand(5, 3)
# # print(x)
# # y = x.view(3, 5)  # view=reshape,transpose=转置,item=将一维张量转为数值
# # print(y)
# # z = x.numpy()  # tensor转换为numpy，两者共同变化
# # print(z)
# # a = np.ones(5)
# # b = th.from_numpy(a)  numpy转换为tensor,两者共同变化
# # print(b)
# use_gpu = th.cuda.is_available()
# print(use_gpu)
x_data = np.random.rand(100)
noise = np.random.normal(0, 0.01, x_data.shape)
y_data = x_data*0.1 + 0.2 + noise
plt.figure()
plt.subplot(1, 2, 1)
plt.scatter(x_data, y_data)
x_data = x_data.reshape(-1, 1)   # 将数据化为一列任意行
y_data = y_data.reshape(-1, 1)
# 把numpy数据变成tensor\n",
x_data = torch.FloatTensor(x_data)
y_data = torch.FloatTensor(y_data)
inputs = Variable(x_data)
target = Variable(y_data)
# 构建神经网络模型",
# 一般把网络中具有可学习参数的层放在__init__()中


class LinearRegression(nn.Module):
    # 定义网络结构，函数一般分为初始化函数和计算函数
    def __init__(self):
        # 初始化nn.Module，父类为库中固定类
        super(LinearRegression, self).__init__()
        self.fc = nn.Linear(1, 1)  # 定义全连接层，定义输入输出神经元个数
        # 定义网络计算

    def forward(self, x):
        out = self.fc(x)
        return out

# 定义模型


model = LinearRegression()
# 定义代价函数
mse_loss = nn.MSELoss()
# 定义优化器
optimizer = optim.SGD(model.parameters(), lr=0.1)  # lr为学习率
for name, parameters in model.named_parameters():    # 查看模型参数
    print('name:{}, param:{}'.format(name, parameters))
for i in range(1001):    # 开始训练
    out = model(inputs)
    # 计算loss
    loss = mse_loss(out, target)
    # 梯度清0
    optimizer.zero_grad()
    # 计算梯度
    loss.backward()
    # 修改权值
    optimizer.step()
    if i % 200 == 0:   # 每200次输出代价函数
        print(i, loss.item())
y_pre = model(inputs)
plt.subplot(1, 2, 2)
plt.scatter(x_data, y_data)
plt.plot(x_data, y_pre.data.numpy(), 'r-', lw=3)
plt.show()
